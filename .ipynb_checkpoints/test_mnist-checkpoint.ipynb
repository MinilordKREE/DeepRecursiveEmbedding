{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad83e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from DRE import DeepRecursiveEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7143d46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9745479af907461c97b6dea1d06b2a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/MNIST/raw/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba4eccb0d2543cbb328aaa1ac7d27a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d8861bf55c43c091376574ee47244e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6e4e90963841ccb3e0c8017139332c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
      "\n",
      "[DRE] Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zuxinrui/miniconda3/envs/delft/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Model loaded\n",
      "[DRE] start------->  time:  Fri Oct 22 05:41:34 2021\n",
      "building P matrix...\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 587.588548\n",
      "[DRE] P length:  1\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 586.005143\n",
      "[DRE] P length:  2\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 582.353874\n",
      "[DRE] P length:  3\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 588.405060\n",
      "[DRE] P length:  4\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 586.852387\n",
      "[DRE] P length:  5\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 601.301499\n",
      "[DRE] P length:  6\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 582.012676\n",
      "[DRE] P length:  7\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 587.342518\n",
      "[DRE] P length:  8\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 590.633428\n",
      "[DRE] P length:  9\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 594.849935\n",
      "[DRE] P length:  10\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 565.090938\n",
      "[DRE] P length:  11\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 576.137009\n",
      "[DRE] P length:  12\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 577.715822\n",
      "[DRE] P length:  13\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 576.706934\n",
      "[DRE] P length:  14\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 596.326953\n",
      "[DRE] P length:  15\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 577.663500\n",
      "[DRE] P length:  16\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 585.504119\n",
      "[DRE] P length:  17\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 577.910394\n",
      "[DRE] P length:  18\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 576.305592\n",
      "[DRE] P length:  19\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 589.498842\n",
      "[DRE] P length:  20\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 581.136740\n",
      "[DRE] P length:  21\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 575.591683\n",
      "[DRE] P length:  22\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 581.639699\n",
      "[DRE] P length:  23\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 1/350:  21%|\u001b[34m██        \u001b[0m| 12500/60000 [00:00<00:00, 87668.26img/s, loss (batch)=2.96]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 589.036711\n",
      "[DRE] P length:  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 1/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100482.27img/s, loss (batch)=2.43]\n",
      "[DRE] Training.. Epoch 2/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 103459.47img/s, loss (batch)=2.17]\n",
      "[DRE] Training.. Epoch 3/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 104412.93img/s, loss (batch)=2.01]\n",
      "[DRE] Training.. Epoch 4/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99030.91img/s, loss (batch)=1.91] \n",
      "[DRE] Training.. Epoch 5/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101687.62img/s, loss (batch)=1.84]\n",
      "[DRE] Training.. Epoch 6/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99517.57img/s, loss (batch)=1.77] \n",
      "[DRE] Training.. Epoch 7/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101385.61img/s, loss (batch)=1.73]\n",
      "[DRE] Training.. Epoch 8/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 98952.80img/s, loss (batch)=1.69]\n",
      "[DRE] Training.. Epoch 9/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 98437.01img/s, loss (batch)=1.66] \n",
      "[DRE] Training.. Epoch 10/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100111.68img/s, loss (batch)=1.63]\n",
      "[DRE] Validating.. Epoch 10/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 143693.86img/s, loss (batch)=tensor(1.7548, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 11/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 102307.88img/s, loss (batch)=1.73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 11/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101421.32img/s, loss (batch)=1.61]\n",
      "[DRE] Training.. Epoch 12/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100935.38img/s, loss (batch)=1.59]\n",
      "[DRE] Training.. Epoch 13/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 98891.63img/s, loss (batch)=1.57] \n",
      "[DRE] Training.. Epoch 14/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101024.56img/s, loss (batch)=1.55]\n",
      "[DRE] Training.. Epoch 15/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101966.26img/s, loss (batch)=1.53]\n",
      "[DRE] Training.. Epoch 16/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101048.94img/s, loss (batch)=1.52]\n",
      "[DRE] Training.. Epoch 17/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101636.40img/s, loss (batch)=1.51]\n",
      "[DRE] Training.. Epoch 18/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99717.50img/s, loss (batch)=1.5]  \n",
      "[DRE] Training.. Epoch 19/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100834.19img/s, loss (batch)=1.49]\n",
      "[DRE] Training.. Epoch 20/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 96086.69img/s, loss (batch)=1.48]\n",
      "[DRE] Validating.. Epoch 20/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 138087.34img/s, loss (batch)=tensor(1.6100, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 21/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 101295.05img/s, loss (batch)=1.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 21/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100691.77img/s, loss (batch)=1.47]\n",
      "[DRE] Training.. Epoch 22/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102883.56img/s, loss (batch)=1.45]\n",
      "[DRE] Training.. Epoch 23/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 103281.57img/s, loss (batch)=1.44]\n",
      "[DRE] Training.. Epoch 24/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101320.01img/s, loss (batch)=1.44]\n",
      "[DRE] Training.. Epoch 25/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101428.51img/s, loss (batch)=1.43]\n",
      "[DRE] Training.. Epoch 26/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101937.43img/s, loss (batch)=1.42]\n",
      "[DRE] Training.. Epoch 27/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100816.74img/s, loss (batch)=1.41]\n",
      "[DRE] Training.. Epoch 28/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101871.33img/s, loss (batch)=1.4] \n",
      "[DRE] Training.. Epoch 29/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100836.78img/s, loss (batch)=1.4] \n",
      "[DRE] Training.. Epoch 30/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102259.57img/s, loss (batch)=1.39]\n",
      "[DRE] Validating.. Epoch 30/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 144390.85img/s, loss (batch)=tensor(1.5411, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 31/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 101329.31img/s, loss (batch)=1.52]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 31/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101570.93img/s, loss (batch)=1.38]\n",
      "[DRE] Training.. Epoch 32/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102738.83img/s, loss (batch)=1.38]\n",
      "[DRE] Training.. Epoch 33/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 103266.86img/s, loss (batch)=1.38]\n",
      "[DRE] Training.. Epoch 34/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102596.96img/s, loss (batch)=1.38]\n",
      "[DRE] Training.. Epoch 35/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101051.50img/s, loss (batch)=1.36]\n",
      "[DRE] Training.. Epoch 36/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102572.16img/s, loss (batch)=1.36]\n",
      "[DRE] Training.. Epoch 37/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 103153.42img/s, loss (batch)=1.35]\n",
      "[DRE] Training.. Epoch 38/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 103378.89img/s, loss (batch)=1.34]\n",
      "[DRE] Training.. Epoch 39/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 103201.98img/s, loss (batch)=1.34]\n",
      "[DRE] Training.. Epoch 40/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102587.09img/s, loss (batch)=1.33]\n",
      "[DRE] Validating.. Epoch 40/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 144734.98img/s, loss (batch)=tensor(1.4843, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 41/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 102721.81img/s, loss (batch)=1.46]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 41/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102085.39img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 42/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102734.67img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 43/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102086.34img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 44/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102988.28img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 45/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100903.16img/s, loss (batch)=1.32]\n",
      "[DRE] Training.. Epoch 46/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102804.00img/s, loss (batch)=1.32]\n",
      "[DRE] Training.. Epoch 47/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102060.34img/s, loss (batch)=1.31]\n",
      "[DRE] Training.. Epoch 48/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102244.74img/s, loss (batch)=1.3] \n",
      "[DRE] Training.. Epoch 49/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102945.81img/s, loss (batch)=1.3] \n",
      "[DRE] Training.. Epoch 50/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101751.18img/s, loss (batch)=1.3] \n",
      "[DRE] Validating.. Epoch 50/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 144297.46img/s, loss (batch)=tensor(1.4608, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 51/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 102679.16img/s, loss (batch)=1.41]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 51/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101602.51img/s, loss (batch)=1.29]\n",
      "[DRE] Training.. Epoch 52/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102041.76img/s, loss (batch)=1.28]\n",
      "[DRE] Training.. Epoch 53/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101787.89img/s, loss (batch)=1.28]\n",
      "[DRE] Training.. Epoch 54/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 103731.85img/s, loss (batch)=1.27]\n",
      "[DRE] Training.. Epoch 55/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100863.17img/s, loss (batch)=1.28]\n",
      "[DRE] Training.. Epoch 56/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102668.87img/s, loss (batch)=1.28]\n",
      "[DRE] Training.. Epoch 57/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102130.54img/s, loss (batch)=1.27]\n",
      "[DRE] Training.. Epoch 58/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 103899.43img/s, loss (batch)=1.26]\n",
      "[DRE] Training.. Epoch 59/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100979.60img/s, loss (batch)=1.26]\n",
      "[DRE] Training.. Epoch 60/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102031.95img/s, loss (batch)=1.25]\n",
      "[DRE] Validating.. Epoch 60/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 145614.66img/s, loss (batch)=tensor(1.4294, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 61/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 101491.53img/s, loss (batch)=1.39]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 61/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102326.64img/s, loss (batch)=1.26]\n",
      "[DRE] Training.. Epoch 62/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102103.82img/s, loss (batch)=1.26]\n",
      "[DRE] Training.. Epoch 63/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 103217.98img/s, loss (batch)=1.25]\n",
      "[DRE] Training.. Epoch 64/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101919.68img/s, loss (batch)=1.24]\n",
      "[DRE] Training.. Epoch 65/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101601.24img/s, loss (batch)=1.24]\n",
      "[DRE] Training.. Epoch 66/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 103316.80img/s, loss (batch)=1.24]\n",
      "[DRE] Training.. Epoch 67/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102137.34img/s, loss (batch)=1.24]\n",
      "[DRE] Training.. Epoch 68/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101396.23img/s, loss (batch)=1.24]\n",
      "[DRE] Training.. Epoch 69/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102316.11img/s, loss (batch)=1.25]\n",
      "[DRE] Training.. Epoch 70/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101304.02img/s, loss (batch)=1.23]\n",
      "[DRE] Validating.. Epoch 70/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 145059.10img/s, loss (batch)=tensor(1.4058, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 71/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 103458.43img/s, loss (batch)=1.37]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 71/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102770.84img/s, loss (batch)=1.23]\n",
      "[DRE] Training.. Epoch 72/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101567.37img/s, loss (batch)=1.23]\n",
      "[DRE] Training.. Epoch 73/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102877.38img/s, loss (batch)=1.23]\n",
      "[DRE] Training.. Epoch 74/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101239.63img/s, loss (batch)=1.25]\n",
      "[DRE] Training.. Epoch 75/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101042.49img/s, loss (batch)=1.22]\n",
      "[DRE] Training.. Epoch 76/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101681.58img/s, loss (batch)=1.22]\n",
      "[DRE] Training.. Epoch 77/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102936.00img/s, loss (batch)=1.23]\n",
      "[DRE] Training.. Epoch 78/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101633.57img/s, loss (batch)=1.22]\n",
      "[DRE] Training.. Epoch 79/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101621.30img/s, loss (batch)=1.22]\n",
      "[DRE] Training.. Epoch 80/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101401.62img/s, loss (batch)=1.2] \n",
      "[DRE] Validating.. Epoch 80/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 146301.53img/s, loss (batch)=tensor(1.3830, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 81/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 106358.10img/s, loss (batch)=1.35]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 81/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102809.04img/s, loss (batch)=1.21]\n",
      "[DRE] Training.. Epoch 82/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101846.01img/s, loss (batch)=1.2] \n",
      "[DRE] Training.. Epoch 83/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102667.99img/s, loss (batch)=1.21]\n",
      "[DRE] Training.. Epoch 84/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102442.48img/s, loss (batch)=1.21]\n",
      "[DRE] Training.. Epoch 85/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101266.52img/s, loss (batch)=1.2] \n",
      "[DRE] Training.. Epoch 86/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102385.67img/s, loss (batch)=1.19]\n",
      "[DRE] Training.. Epoch 87/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101384.91img/s, loss (batch)=1.19]\n",
      "[DRE] Training.. Epoch 88/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101082.46img/s, loss (batch)=1.2] \n",
      "[DRE] Training.. Epoch 89/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101505.02img/s, loss (batch)=1.19]\n",
      "[DRE] Training.. Epoch 90/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101545.11img/s, loss (batch)=1.2] \n",
      "[DRE] Validating.. Epoch 90/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 146402.56img/s, loss (batch)=tensor(1.3768, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 91/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 105570.41img/s, loss (batch)=1.33]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 91/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102224.14img/s, loss (batch)=1.2] \n",
      "[DRE] Training.. Epoch 92/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101501.70img/s, loss (batch)=1.21]\n",
      "[DRE] Training.. Epoch 93/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101243.50img/s, loss (batch)=1.21]\n",
      "[DRE] Training.. Epoch 94/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101834.89img/s, loss (batch)=1.19]\n",
      "[DRE] Training.. Epoch 95/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 103535.15img/s, loss (batch)=1.19]\n",
      "[DRE] Training.. Epoch 96/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102011.07img/s, loss (batch)=1.18]\n",
      "[DRE] Training.. Epoch 97/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100948.21img/s, loss (batch)=1.18]\n",
      "[DRE] Training.. Epoch 98/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101754.59img/s, loss (batch)=1.19]\n",
      "[DRE] Training.. Epoch 99/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100919.63img/s, loss (batch)=1.18]\n",
      "[DRE] Training.. Epoch 100/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101652.66img/s, loss (batch)=1.18]\n",
      "[DRE] Validating.. Epoch 100/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 145888.83img/s, loss (batch)=tensor(1.3588, device='cuda:0', dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n",
      "building P matrix...\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.719408\n",
      "[DRE] P length:  1\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.711296\n",
      "[DRE] P length:  2\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.681302\n",
      "[DRE] P length:  3\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.732173\n",
      "[DRE] P length:  4\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.666964\n",
      "[DRE] P length:  5\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.948594\n",
      "[DRE] P length:  6\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.781571\n",
      "[DRE] P length:  7\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.780512\n",
      "[DRE] P length:  8\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.720491\n",
      "[DRE] P length:  9\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.831803\n",
      "[DRE] P length:  10\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.429342\n",
      "[DRE] P length:  11\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.671861\n",
      "[DRE] P length:  12\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.840769\n",
      "[DRE] P length:  13\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.731202\n",
      "[DRE] P length:  14\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.881085\n",
      "[DRE] P length:  15\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.781813\n",
      "[DRE] P length:  16\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.817374\n",
      "[DRE] P length:  17\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.777853\n",
      "[DRE] P length:  18\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.823162\n",
      "[DRE] P length:  19\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.876804\n",
      "[DRE] P length:  20\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.713926\n",
      "[DRE] P length:  21\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.733669\n",
      "[DRE] P length:  22\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.650689\n",
      "[DRE] P length:  23\n",
      "[DRE] recursive step 1 data shape:  (2500, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 101/350:  21%|\u001b[34m██        \u001b[0m| 12500/60000 [00:00<00:00, 101865.41img/s, loss (batch)=0.638]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 4.434555\n",
      "[DRE] P length:  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 101/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100655.57img/s, loss (batch)=0.563]\n",
      "[DRE] Training.. Epoch 102/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101180.00img/s, loss (batch)=0.526]\n",
      "[DRE] Training.. Epoch 103/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101316.63img/s, loss (batch)=0.509]\n",
      "[DRE] Training.. Epoch 104/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100871.29img/s, loss (batch)=0.498]\n",
      "[DRE] Training.. Epoch 105/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101900.49img/s, loss (batch)=0.491]\n",
      "[DRE] Training.. Epoch 106/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102445.94img/s, loss (batch)=0.488]\n",
      "[DRE] Training.. Epoch 107/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102034.77img/s, loss (batch)=0.486]\n",
      "[DRE] Training.. Epoch 108/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101495.52img/s, loss (batch)=0.479]\n",
      "[DRE] Training.. Epoch 109/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100617.05img/s, loss (batch)=0.475]\n",
      "[DRE] Training.. Epoch 110/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102638.55img/s, loss (batch)=0.47] \n",
      "[DRE] Validating.. Epoch 110/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 144576.50img/s, loss (batch)=tensor(0.5182, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 111/350:  25%|\u001b[34m██▌       \u001b[0m| 15000/60000 [00:00<00:00, 97957.48img/s, loss (batch)=0.49] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 111/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100523.49img/s, loss (batch)=0.475]\n",
      "[DRE] Training.. Epoch 112/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101291.67img/s, loss (batch)=0.463]\n",
      "[DRE] Training.. Epoch 113/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100668.89img/s, loss (batch)=0.462]\n",
      "[DRE] Training.. Epoch 114/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102072.10img/s, loss (batch)=0.46] \n",
      "[DRE] Training.. Epoch 115/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100442.56img/s, loss (batch)=0.465]\n",
      "[DRE] Training.. Epoch 116/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102280.97img/s, loss (batch)=0.458]\n",
      "[DRE] Training.. Epoch 117/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100451.66img/s, loss (batch)=0.457]\n",
      "[DRE] Training.. Epoch 118/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100643.45img/s, loss (batch)=0.457]\n",
      "[DRE] Training.. Epoch 119/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101982.00img/s, loss (batch)=0.453]\n",
      "[DRE] Training.. Epoch 120/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100713.33img/s, loss (batch)=0.456]\n",
      "[DRE] Validating.. Epoch 120/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 146801.81img/s, loss (batch)=tensor(0.5135, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 121/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 102586.74img/s, loss (batch)=0.48] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 121/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102164.67img/s, loss (batch)=0.454]\n",
      "[DRE] Training.. Epoch 122/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100606.03img/s, loss (batch)=0.452]\n",
      "[DRE] Training.. Epoch 123/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99354.71img/s, loss (batch)=0.456]\n",
      "[DRE] Training.. Epoch 124/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101582.70img/s, loss (batch)=0.462]\n",
      "[DRE] Training.. Epoch 125/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99669.47img/s, loss (batch)=0.46]  \n",
      "[DRE] Training.. Epoch 126/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102229.49img/s, loss (batch)=0.458]\n",
      "[DRE] Training.. Epoch 127/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100092.49img/s, loss (batch)=0.455]\n",
      "[DRE] Training.. Epoch 128/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100386.39img/s, loss (batch)=0.455]\n",
      "[DRE] Training.. Epoch 129/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101371.52img/s, loss (batch)=0.451]\n",
      "[DRE] Training.. Epoch 130/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 104123.01img/s, loss (batch)=0.453]\n",
      "[DRE] Validating.. Epoch 130/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 146935.10img/s, loss (batch)=tensor(0.5129, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 131/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 105654.02img/s, loss (batch)=0.484]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 131/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101266.28img/s, loss (batch)=0.447]\n",
      "[DRE] Training.. Epoch 132/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101346.70img/s, loss (batch)=0.447]\n",
      "[DRE] Training.. Epoch 133/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100994.15img/s, loss (batch)=0.44] \n",
      "[DRE] Training.. Epoch 134/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102651.41img/s, loss (batch)=0.442]\n",
      "[DRE] Training.. Epoch 135/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 103061.41img/s, loss (batch)=0.449]\n",
      "[DRE] Training.. Epoch 136/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101588.24img/s, loss (batch)=0.44] \n",
      "[DRE] Training.. Epoch 137/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101519.39img/s, loss (batch)=0.44] \n",
      "[DRE] Training.. Epoch 138/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 98906.52img/s, loss (batch)=0.442]\n",
      "[DRE] Training.. Epoch 139/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101502.03img/s, loss (batch)=0.437]\n",
      "[DRE] Training.. Epoch 140/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101350.74img/s, loss (batch)=0.435]\n",
      "[DRE] Validating.. Epoch 140/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 140384.38img/s, loss (batch)=tensor(0.4975, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 141/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 105953.58img/s, loss (batch)=0.458]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 141/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99567.93img/s, loss (batch)=0.436] \n",
      "[DRE] Training.. Epoch 142/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102038.78img/s, loss (batch)=0.437]\n",
      "[DRE] Training.. Epoch 143/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 98103.65img/s, loss (batch)=0.439] \n",
      "[DRE] Training.. Epoch 144/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 97556.06img/s, loss (batch)=0.435]\n",
      "[DRE] Training.. Epoch 145/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 97405.62img/s, loss (batch)=0.433]\n",
      "[DRE] Training.. Epoch 146/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 97615.88img/s, loss (batch)=0.437]\n",
      "[DRE] Training.. Epoch 147/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102507.78img/s, loss (batch)=0.434]\n",
      "[DRE] Training.. Epoch 148/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101429.94img/s, loss (batch)=0.438]\n",
      "[DRE] Training.. Epoch 149/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101880.19img/s, loss (batch)=0.437]\n",
      "[DRE] Training.. Epoch 150/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 103376.01img/s, loss (batch)=0.434]\n",
      "[DRE] Validating.. Epoch 150/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 145269.02img/s, loss (batch)=tensor(0.4964, device='cuda:0', dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n",
      "building P matrix...\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.267814\n",
      "[DRE] P length:  1\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.296123\n",
      "[DRE] P length:  2\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.282522\n",
      "[DRE] P length:  3\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.319613\n",
      "[DRE] P length:  4\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.270220\n",
      "[DRE] P length:  5\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.336442\n",
      "[DRE] P length:  6\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.314418\n",
      "[DRE] P length:  7\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.324740\n",
      "[DRE] P length:  8\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.316250\n",
      "[DRE] P length:  9\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.318226\n",
      "[DRE] P length:  10\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.234393\n",
      "[DRE] P length:  11\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.308382\n",
      "[DRE] P length:  12\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.323040\n",
      "[DRE] P length:  13\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.292544\n",
      "[DRE] P length:  14\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.351275\n",
      "[DRE] P length:  15\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.337717\n",
      "[DRE] P length:  16\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.286449\n",
      "[DRE] P length:  17\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.322346\n",
      "[DRE] P length:  18\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.356430\n",
      "[DRE] P length:  19\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.377206\n",
      "[DRE] P length:  20\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.314138\n",
      "[DRE] P length:  21\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.338669\n",
      "[DRE] P length:  22\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.302707\n",
      "[DRE] P length:  23\n",
      "[DRE] recursive step 2 data shape:  (2500, 500)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 1.183531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 151/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 104679.85img/s, loss (batch)=0.399]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] P length:  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 151/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106012.43img/s, loss (batch)=0.379]\n",
      "[DRE] Training.. Epoch 152/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106769.21img/s, loss (batch)=0.369]\n",
      "[DRE] Training.. Epoch 153/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 105937.50img/s, loss (batch)=0.362]\n",
      "[DRE] Training.. Epoch 154/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106372.79img/s, loss (batch)=0.359]\n",
      "[DRE] Training.. Epoch 155/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106690.63img/s, loss (batch)=0.363]\n",
      "[DRE] Training.. Epoch 156/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106053.84img/s, loss (batch)=0.361]\n",
      "[DRE] Training.. Epoch 157/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 103522.42img/s, loss (batch)=0.361]\n",
      "[DRE] Training.. Epoch 158/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102980.19img/s, loss (batch)=0.361]\n",
      "[DRE] Training.. Epoch 159/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 104661.97img/s, loss (batch)=0.37] \n",
      "[DRE] Training.. Epoch 160/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101334.09img/s, loss (batch)=0.351]\n",
      "[DRE] Validating.. Epoch 160/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 139219.46img/s, loss (batch)=tensor(0.3844, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 161/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 105721.34img/s, loss (batch)=0.36] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 161/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102076.86img/s, loss (batch)=0.34] \n",
      "[DRE] Training.. Epoch 162/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100701.40img/s, loss (batch)=0.339]\n",
      "[DRE] Training.. Epoch 163/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 104585.37img/s, loss (batch)=0.336]\n",
      "[DRE] Training.. Epoch 164/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106263.33img/s, loss (batch)=0.333]\n",
      "[DRE] Training.. Epoch 165/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 105970.24img/s, loss (batch)=0.336]\n",
      "[DRE] Training.. Epoch 166/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106524.94img/s, loss (batch)=0.329]\n",
      "[DRE] Training.. Epoch 167/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106036.86img/s, loss (batch)=0.33] \n",
      "[DRE] Training.. Epoch 168/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106497.44img/s, loss (batch)=0.327]\n",
      "[DRE] Training.. Epoch 169/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106811.13img/s, loss (batch)=0.323]\n",
      "[DRE] Training.. Epoch 170/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 105525.71img/s, loss (batch)=0.319]\n",
      "[DRE] Validating.. Epoch 170/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 136772.27img/s, loss (batch)=tensor(0.3644, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 171/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 99252.56img/s, loss (batch)=0.34] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 171/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101120.20img/s, loss (batch)=0.322]\n",
      "[DRE] Training.. Epoch 172/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102783.18img/s, loss (batch)=0.323]\n",
      "[DRE] Training.. Epoch 173/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 92591.09img/s, loss (batch)=0.328] \n",
      "[DRE] Training.. Epoch 174/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 97168.72img/s, loss (batch)=0.332]\n",
      "[DRE] Training.. Epoch 175/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99112.35img/s, loss (batch)=0.329] \n",
      "[DRE] Training.. Epoch 176/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 105847.23img/s, loss (batch)=0.329]\n",
      "[DRE] Training.. Epoch 177/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106570.59img/s, loss (batch)=0.331]\n",
      "[DRE] Training.. Epoch 178/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106429.79img/s, loss (batch)=0.331]\n",
      "[DRE] Training.. Epoch 179/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106828.72img/s, loss (batch)=0.325]\n",
      "[DRE] Training.. Epoch 180/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106497.12img/s, loss (batch)=0.321]\n",
      "[DRE] Validating.. Epoch 180/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 143332.86img/s, loss (batch)=tensor(0.3640, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 181/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 104534.59img/s, loss (batch)=0.341]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 181/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102127.48img/s, loss (batch)=0.318]\n",
      "[DRE] Training.. Epoch 182/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 104482.64img/s, loss (batch)=0.322]\n",
      "[DRE] Training.. Epoch 183/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 104049.40img/s, loss (batch)=0.319]\n",
      "[DRE] Training.. Epoch 184/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 104573.55img/s, loss (batch)=0.32] \n",
      "[DRE] Training.. Epoch 185/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 104789.27img/s, loss (batch)=0.318]\n",
      "[DRE] Training.. Epoch 186/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 105617.39img/s, loss (batch)=0.318]\n",
      "[DRE] Training.. Epoch 187/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106656.27img/s, loss (batch)=0.32] \n",
      "[DRE] Training.. Epoch 188/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106569.87img/s, loss (batch)=0.318]\n",
      "[DRE] Training.. Epoch 189/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 107643.14img/s, loss (batch)=0.312]\n",
      "[DRE] Training.. Epoch 190/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106715.11img/s, loss (batch)=0.31] \n",
      "[DRE] Validating.. Epoch 190/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 144993.99img/s, loss (batch)=tensor(0.3623, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 191/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 108137.18img/s, loss (batch)=0.328]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 191/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 107540.19img/s, loss (batch)=0.311]\n",
      "[DRE] Training.. Epoch 192/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 107657.00img/s, loss (batch)=0.31] \n",
      "[DRE] Training.. Epoch 193/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 107589.66img/s, loss (batch)=0.307]\n",
      "[DRE] Training.. Epoch 194/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 107566.48img/s, loss (batch)=0.311]\n",
      "[DRE] Training.. Epoch 195/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 107285.20img/s, loss (batch)=0.317]\n",
      "[DRE] Training.. Epoch 196/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 106732.53img/s, loss (batch)=0.315]\n",
      "[DRE] Training.. Epoch 197/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 107001.42img/s, loss (batch)=0.314]\n",
      "[DRE] Training.. Epoch 198/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 107526.27img/s, loss (batch)=0.312]\n",
      "[DRE] Training.. Epoch 199/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 107699.80img/s, loss (batch)=0.314]\n",
      "[DRE] Training.. Epoch 200/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 107680.07img/s, loss (batch)=0.313]\n",
      "[DRE] Validating.. Epoch 200/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 144671.33img/s, loss (batch)=tensor(0.3637, device='cuda:0', dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n",
      "building P matrix...\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.590409\n",
      "[DRE] P length:  1\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.606690\n",
      "[DRE] P length:  2\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.600513\n",
      "[DRE] P length:  3\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.622052\n",
      "[DRE] P length:  4\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.587995\n",
      "[DRE] P length:  5\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.618874\n",
      "[DRE] P length:  6\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.626319\n",
      "[DRE] P length:  7\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.614104\n",
      "[DRE] P length:  8\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.604430\n",
      "[DRE] P length:  9\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.607825\n",
      "[DRE] P length:  10\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.567797\n",
      "[DRE] P length:  11\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.623176\n",
      "[DRE] P length:  12\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.612456\n",
      "[DRE] P length:  13\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.605473\n",
      "[DRE] P length:  14\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.622284\n",
      "[DRE] P length:  15\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.620776\n",
      "[DRE] P length:  16\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.594463\n",
      "[DRE] P length:  17\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.616404\n",
      "[DRE] P length:  18\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.630162\n",
      "[DRE] P length:  19\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.633949\n",
      "[DRE] P length:  20\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.616979\n",
      "[DRE] P length:  21\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.631679\n",
      "[DRE] P length:  22\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.617605\n",
      "[DRE] P length:  23\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] Computed conditional probabilities for sample 1000 / 2500\n",
      "[DRE] Computed conditional probabilities for sample 2000 / 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 201/350:  21%|\u001b[34m██        \u001b[0m| 12500/60000 [00:00<00:00, 96663.44img/s, loss (batch)=0.294]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Computed conditional probabilities for sample 2500 / 2500\n",
      "[DRE] Mean sigma: 0.566161\n",
      "[DRE] P length:  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 201/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99499.20img/s, loss (batch)=0.306] \n",
      "[DRE] Training.. Epoch 202/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100177.99img/s, loss (batch)=0.298]\n",
      "[DRE] Training.. Epoch 203/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102006.56img/s, loss (batch)=0.299]\n",
      "[DRE] Training.. Epoch 204/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102587.30img/s, loss (batch)=0.303]\n",
      "[DRE] Training.. Epoch 205/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100777.05img/s, loss (batch)=0.31] \n",
      "[DRE] Training.. Epoch 206/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99117.42img/s, loss (batch)=0.307] \n",
      "[DRE] Training.. Epoch 207/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101910.64img/s, loss (batch)=0.316]\n",
      "[DRE] Training.. Epoch 208/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 97370.39img/s, loss (batch)=0.302]\n",
      "[DRE] Training.. Epoch 209/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100250.98img/s, loss (batch)=0.307]\n",
      "[DRE] Training.. Epoch 210/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101942.80img/s, loss (batch)=0.302]\n",
      "[DRE] Validating.. Epoch 210/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 144777.28img/s, loss (batch)=tensor(0.3201, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 211/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 103494.99img/s, loss (batch)=0.3]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 211/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 104086.84img/s, loss (batch)=0.294]\n",
      "[DRE] Training.. Epoch 212/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 104010.26img/s, loss (batch)=0.288]\n",
      "[DRE] Training.. Epoch 213/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102204.21img/s, loss (batch)=0.295]\n",
      "[DRE] Training.. Epoch 214/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99195.25img/s, loss (batch)=0.29]  \n",
      "[DRE] Training.. Epoch 215/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101265.09img/s, loss (batch)=0.293]\n",
      "[DRE] Training.. Epoch 216/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99347.03img/s, loss (batch)=0.293] \n",
      "[DRE] Training.. Epoch 217/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 98563.27img/s, loss (batch)=0.291] \n",
      "[DRE] Training.. Epoch 218/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101144.74img/s, loss (batch)=0.286]\n",
      "[DRE] Training.. Epoch 219/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102923.54img/s, loss (batch)=0.279]\n",
      "[DRE] Training.. Epoch 220/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 102243.28img/s, loss (batch)=0.275]\n",
      "[DRE] Validating.. Epoch 220/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 143609.07img/s, loss (batch)=tensor(0.3049, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 221/350:  29%|\u001b[34m██▉       \u001b[0m| 17500/60000 [00:00<00:00, 101642.64img/s, loss (batch)=0.28] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 221/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101555.48img/s, loss (batch)=0.282]\n",
      "[DRE] Training.. Epoch 222/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100319.52img/s, loss (batch)=0.285]\n",
      "[DRE] Training.. Epoch 223/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99370.60img/s, loss (batch)=0.276]\n",
      "[DRE] Training.. Epoch 224/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99768.18img/s, loss (batch)=0.276] \n",
      "[DRE] Training.. Epoch 225/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 97875.03img/s, loss (batch)=0.284] \n",
      "[DRE] Training.. Epoch 226/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 97270.16img/s, loss (batch)=0.284]\n",
      "[DRE] Training.. Epoch 227/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 96579.56img/s, loss (batch)=0.279]\n",
      "[DRE] Training.. Epoch 228/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101344.70img/s, loss (batch)=0.278]\n",
      "[DRE] Training.. Epoch 229/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 101725.80img/s, loss (batch)=0.277]\n",
      "[DRE] Training.. Epoch 230/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100395.76img/s, loss (batch)=0.283]\n",
      "[DRE] Validating.. Epoch 230/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 143437.18img/s, loss (batch)=tensor(0.3305, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 231/350:  25%|\u001b[34m██▌       \u001b[0m| 15000/60000 [00:00<00:00, 95806.52img/s, loss (batch)=0.271]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 231/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 96379.50img/s, loss (batch)=0.279]\n",
      "[DRE] Training.. Epoch 232/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99208.39img/s, loss (batch)=0.283] \n",
      "[DRE] Training.. Epoch 233/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100052.26img/s, loss (batch)=0.273]\n",
      "[DRE] Training.. Epoch 234/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99752.63img/s, loss (batch)=0.269] \n",
      "[DRE] Training.. Epoch 235/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99129.17img/s, loss (batch)=0.273] \n",
      "[DRE] Training.. Epoch 236/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 98232.78img/s, loss (batch)=0.27] \n",
      "[DRE] Training.. Epoch 237/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99463.76img/s, loss (batch)=0.273] \n",
      "[DRE] Training.. Epoch 238/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99086.86img/s, loss (batch)=0.275]\n",
      "[DRE] Training.. Epoch 239/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100038.97img/s, loss (batch)=0.27] \n",
      "[DRE] Training.. Epoch 240/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 96410.92img/s, loss (batch)=0.27] \n",
      "[DRE] Validating.. Epoch 240/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 141443.65img/s, loss (batch)=tensor(0.3078, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 241/350:  25%|\u001b[34m██▌       \u001b[0m| 15000/60000 [00:00<00:00, 98964.98img/s, loss (batch)=0.268]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 241/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 98788.57img/s, loss (batch)=0.272]\n",
      "[DRE] Training.. Epoch 242/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99363.50img/s, loss (batch)=0.272] \n",
      "[DRE] Training.. Epoch 243/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99300.30img/s, loss (batch)=0.27]  \n",
      "[DRE] Training.. Epoch 244/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99996.08img/s, loss (batch)=0.269] \n",
      "[DRE] Training.. Epoch 245/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99391.21img/s, loss (batch)=0.264] \n",
      "[DRE] Training.. Epoch 246/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100311.64img/s, loss (batch)=0.265]\n",
      "[DRE] Training.. Epoch 247/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99681.35img/s, loss (batch)=0.264]\n",
      "[DRE] Training.. Epoch 248/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 100940.32img/s, loss (batch)=0.265]\n",
      "[DRE] Training.. Epoch 249/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99705.72img/s, loss (batch)=0.264]\n",
      "[DRE] Training.. Epoch 250/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 99798.56img/s, loss (batch)=0.264] \n",
      "[DRE] Validating.. Epoch 250/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 141612.23img/s, loss (batch)=tensor(0.3000, device='cuda:0', dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n",
      "building P matrix...\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  1\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  2\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  3\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  4\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  5\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  6\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  7\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  8\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  9\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  10\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  11\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  12\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  13\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  14\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  15\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  16\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  17\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  18\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  19\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  20\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  21\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  22\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 251/350:   8%|\u001b[34m▊         \u001b[0m| 5000/60000 [00:00<00:00, 57793.48img/s, loss (batch)=1.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] P length:  23\n",
      "[DRE] recursive step 3 data shape:  (2500, 100)\n",
      "[DRE] P length:  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 251/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 87593.87img/s, loss (batch)=1.64]\n",
      "[DRE] Training.. Epoch 252/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 88249.83img/s, loss (batch)=1.6] \n",
      "[DRE] Training.. Epoch 253/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 87269.04img/s, loss (batch)=1.55]\n",
      "[DRE] Training.. Epoch 254/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 87584.08img/s, loss (batch)=1.54]\n",
      "[DRE] Training.. Epoch 255/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 88271.96img/s, loss (batch)=1.52]\n",
      "[DRE] Training.. Epoch 256/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 88135.84img/s, loss (batch)=1.53]\n",
      "[DRE] Training.. Epoch 257/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 88097.68img/s, loss (batch)=1.51]\n",
      "[DRE] Training.. Epoch 258/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 88216.11img/s, loss (batch)=1.5] \n",
      "[DRE] Training.. Epoch 259/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 87087.62img/s, loss (batch)=1.49]\n",
      "[DRE] Training.. Epoch 260/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85681.24img/s, loss (batch)=1.48]\n",
      "[DRE] Validating.. Epoch 260/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 129413.35img/s, loss (batch)=tensor(1.4845, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 261/350:  21%|\u001b[34m██        \u001b[0m| 12500/60000 [00:00<00:00, 87411.20img/s, loss (batch)=1.45]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 261/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82866.22img/s, loss (batch)=1.47]\n",
      "[DRE] Training.. Epoch 262/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83272.45img/s, loss (batch)=1.46]\n",
      "[DRE] Training.. Epoch 263/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85085.36img/s, loss (batch)=1.48]\n",
      "[DRE] Training.. Epoch 264/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85544.88img/s, loss (batch)=1.45]\n",
      "[DRE] Training.. Epoch 265/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85837.89img/s, loss (batch)=1.45]\n",
      "[DRE] Training.. Epoch 266/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82444.05img/s, loss (batch)=1.45]\n",
      "[DRE] Training.. Epoch 267/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83941.96img/s, loss (batch)=1.43]\n",
      "[DRE] Training.. Epoch 268/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82910.42img/s, loss (batch)=1.45]\n",
      "[DRE] Training.. Epoch 269/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82247.19img/s, loss (batch)=1.45]\n",
      "[DRE] Training.. Epoch 270/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82693.88img/s, loss (batch)=1.44]\n",
      "[DRE] Validating.. Epoch 270/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 120587.60img/s, loss (batch)=tensor(1.4437, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 271/350:  21%|\u001b[34m██        \u001b[0m| 12500/60000 [00:00<00:00, 86625.17img/s, loss (batch)=1.4] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 271/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84371.87img/s, loss (batch)=1.44]\n",
      "[DRE] Training.. Epoch 272/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83936.78img/s, loss (batch)=1.43]\n",
      "[DRE] Training.. Epoch 273/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84711.42img/s, loss (batch)=1.42]\n",
      "[DRE] Training.. Epoch 274/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84320.89img/s, loss (batch)=1.42]\n",
      "[DRE] Training.. Epoch 275/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83844.94img/s, loss (batch)=1.41]\n",
      "[DRE] Training.. Epoch 276/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85028.81img/s, loss (batch)=1.42]\n",
      "[DRE] Training.. Epoch 277/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84988.75img/s, loss (batch)=1.42]\n",
      "[DRE] Training.. Epoch 278/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85425.01img/s, loss (batch)=1.43]\n",
      "[DRE] Training.. Epoch 279/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84408.40img/s, loss (batch)=1.42]\n",
      "[DRE] Training.. Epoch 280/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84313.38img/s, loss (batch)=1.41]\n",
      "[DRE] Validating.. Epoch 280/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 123759.92img/s, loss (batch)=tensor(1.4248, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 281/350:  21%|\u001b[34m██        \u001b[0m| 12500/60000 [00:00<00:00, 85700.18img/s, loss (batch)=1.36]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 281/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85857.95img/s, loss (batch)=1.4] \n",
      "[DRE] Training.. Epoch 282/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83843.21img/s, loss (batch)=1.4] \n",
      "[DRE] Training.. Epoch 283/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82576.09img/s, loss (batch)=1.39]\n",
      "[DRE] Training.. Epoch 284/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85154.23img/s, loss (batch)=1.39]\n",
      "[DRE] Training.. Epoch 285/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83782.16img/s, loss (batch)=1.4] \n",
      "[DRE] Training.. Epoch 286/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84832.04img/s, loss (batch)=1.39]\n",
      "[DRE] Training.. Epoch 287/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85260.19img/s, loss (batch)=1.39]\n",
      "[DRE] Training.. Epoch 288/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83241.18img/s, loss (batch)=1.39]\n",
      "[DRE] Training.. Epoch 289/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84402.68img/s, loss (batch)=1.4] \n",
      "[DRE] Training.. Epoch 290/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84596.35img/s, loss (batch)=1.39]\n",
      "[DRE] Validating.. Epoch 290/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 122342.12img/s, loss (batch)=tensor(1.4026, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 291/350:  21%|\u001b[34m██        \u001b[0m| 12500/60000 [00:00<00:00, 84681.75img/s, loss (batch)=1.34]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 291/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84852.92img/s, loss (batch)=1.38]\n",
      "[DRE] Training.. Epoch 292/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85009.08img/s, loss (batch)=1.38]\n",
      "[DRE] Training.. Epoch 293/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 81968.83img/s, loss (batch)=1.38]\n",
      "[DRE] Training.. Epoch 294/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82096.59img/s, loss (batch)=1.37]\n",
      "[DRE] Training.. Epoch 295/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 81745.55img/s, loss (batch)=1.37]\n",
      "[DRE] Training.. Epoch 296/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 81302.63img/s, loss (batch)=1.37]\n",
      "[DRE] Training.. Epoch 297/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82168.67img/s, loss (batch)=1.37]\n",
      "[DRE] Training.. Epoch 298/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84211.53img/s, loss (batch)=1.38]\n",
      "[DRE] Training.. Epoch 299/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83106.84img/s, loss (batch)=1.38]\n",
      "[DRE] Training.. Epoch 300/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 81501.61img/s, loss (batch)=1.38]\n",
      "[DRE] Validating.. Epoch 300/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 120037.61img/s, loss (batch)=tensor(1.3853, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 301/350:  21%|\u001b[34m██        \u001b[0m| 12500/60000 [00:00<00:00, 84175.98img/s, loss (batch)=1.33]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 301/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83293.94img/s, loss (batch)=1.38]\n",
      "[DRE] Training.. Epoch 302/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83727.39img/s, loss (batch)=1.38]\n",
      "[DRE] Training.. Epoch 303/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82450.29img/s, loss (batch)=1.36]\n",
      "[DRE] Training.. Epoch 304/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83435.89img/s, loss (batch)=1.36]\n",
      "[DRE] Training.. Epoch 305/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83189.01img/s, loss (batch)=1.37]\n",
      "[DRE] Training.. Epoch 306/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85911.71img/s, loss (batch)=1.37]\n",
      "[DRE] Training.. Epoch 307/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82292.54img/s, loss (batch)=1.36]\n",
      "[DRE] Training.. Epoch 308/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83215.89img/s, loss (batch)=1.36]\n",
      "[DRE] Training.. Epoch 309/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84456.87img/s, loss (batch)=1.36]\n",
      "[DRE] Training.. Epoch 310/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 86451.44img/s, loss (batch)=1.35]\n",
      "[DRE] Validating.. Epoch 310/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 125344.85img/s, loss (batch)=tensor(1.3754, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 311/350:  21%|\u001b[34m██        \u001b[0m| 12500/60000 [00:00<00:00, 84178.35img/s, loss (batch)=1.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 311/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 81958.95img/s, loss (batch)=1.36]\n",
      "[DRE] Training.. Epoch 312/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82304.11img/s, loss (batch)=1.37]\n",
      "[DRE] Training.. Epoch 313/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82578.40img/s, loss (batch)=1.36]\n",
      "[DRE] Training.. Epoch 314/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82099.27img/s, loss (batch)=1.36]\n",
      "[DRE] Training.. Epoch 315/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84029.24img/s, loss (batch)=1.36]\n",
      "[DRE] Training.. Epoch 316/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85109.27img/s, loss (batch)=1.35]\n",
      "[DRE] Training.. Epoch 317/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 81183.90img/s, loss (batch)=1.34]\n",
      "[DRE] Training.. Epoch 318/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82449.32img/s, loss (batch)=1.34]\n",
      "[DRE] Training.. Epoch 319/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84352.41img/s, loss (batch)=1.35]\n",
      "[DRE] Training.. Epoch 320/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83166.36img/s, loss (batch)=1.35]\n",
      "[DRE] Validating.. Epoch 320/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 117952.93img/s, loss (batch)=tensor(1.3535, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 321/350:  21%|\u001b[34m██        \u001b[0m| 12500/60000 [00:00<00:00, 83133.06img/s, loss (batch)=1.29]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 321/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83057.20img/s, loss (batch)=1.36]\n",
      "[DRE] Training.. Epoch 322/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85782.77img/s, loss (batch)=1.35]\n",
      "[DRE] Training.. Epoch 323/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82351.92img/s, loss (batch)=1.35]\n",
      "[DRE] Training.. Epoch 324/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 86355.83img/s, loss (batch)=1.34]\n",
      "[DRE] Training.. Epoch 325/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 88411.01img/s, loss (batch)=1.34]\n",
      "[DRE] Training.. Epoch 326/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83786.07img/s, loss (batch)=1.34]\n",
      "[DRE] Training.. Epoch 327/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 86740.39img/s, loss (batch)=1.34]\n",
      "[DRE] Training.. Epoch 328/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 88802.20img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 329/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85033.35img/s, loss (batch)=1.34]\n",
      "[DRE] Training.. Epoch 330/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85257.79img/s, loss (batch)=1.33]\n",
      "[DRE] Validating.. Epoch 330/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 126351.58img/s, loss (batch)=tensor(1.3438, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 331/350:  21%|\u001b[34m██        \u001b[0m| 12500/60000 [00:00<00:00, 90228.80img/s, loss (batch)=1.29]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 331/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85891.12img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 332/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83437.49img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 333/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 86824.60img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 334/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85167.86img/s, loss (batch)=1.34]\n",
      "[DRE] Training.. Epoch 335/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83486.98img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 336/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84319.65img/s, loss (batch)=1.34]\n",
      "[DRE] Training.. Epoch 337/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 83744.69img/s, loss (batch)=1.34]\n",
      "[DRE] Training.. Epoch 338/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85369.81img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 339/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85400.78img/s, loss (batch)=1.34]\n",
      "[DRE] Training.. Epoch 340/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84511.98img/s, loss (batch)=1.33]\n",
      "[DRE] Validating.. Epoch 340/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 126700.18img/s, loss (batch)=tensor(1.3508, device='cuda:0', dtype=torch.float64)]\n",
      "[DRE] Training.. Epoch 341/350:  21%|\u001b[34m██        \u001b[0m| 12500/60000 [00:00<00:00, 83679.22img/s, loss (batch)=1.28]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DRE] Training.. Epoch 341/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 86435.32img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 342/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 82885.62img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 343/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85130.03img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 344/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85791.77img/s, loss (batch)=1.34]\n",
      "[DRE] Training.. Epoch 345/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 86177.28img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 346/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85160.16img/s, loss (batch)=1.32]\n",
      "[DRE] Training.. Epoch 347/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 85894.17img/s, loss (batch)=1.32]\n",
      "[DRE] Training.. Epoch 348/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 86228.06img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 349/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 84423.89img/s, loss (batch)=1.33]\n",
      "[DRE] Training.. Epoch 350/350: 100%|\u001b[34m██████████\u001b[0m| 60000/60000 [00:00<00:00, 87274.82img/s, loss (batch)=1.33]\n",
      "[DRE] Validating.. Epoch 350/350: 100%|\u001b[32m██████████\u001b[0m| 60000/60000 [00:00<00:00, 126284.69img/s, loss (batch)=tensor(1.3378, device='cuda:0', dtype=torch.float64)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DRE] Best accuracy, saving the weights...\n",
      "[DRE] training time:  411.198903799057\n",
      "[DRE] ------->complete.  time:  Fri Oct 22 05:48:25 2021\n",
      "fitting time: 411.29884028434753s\n"
     ]
    }
   ],
   "source": [
    "# Deep Recursive Embedding test code using MNIST/Fashion-MNIST datasets loaded with torchvision\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "x_train = torchvision.datasets.MNIST(root='./datasets', train=True, transform=transform_train,\n",
    "                                     download=True)\n",
    "x_train_targets = np.int16(x_train.targets)\n",
    "x_train = np.array(x_train.data).astype('float32')  # useful for GPU accelerating\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "\n",
    "dre = DeepRecursiveEmbedding(dre_type='fc',\n",
    "                             n_pre_epochs=100,\n",
    "                             num_recursive_tsne_epochs=50,\n",
    "                             num_recursive_umap_epochs=100,\n",
    "                             learning_rate=1e-3,\n",
    "                             batch_size=2500,\n",
    "                             random_shuffle=False,  # for plotting with labels, set to 'False'\n",
    "                             save_directory='./',\n",
    "                             )\n",
    "# dre.labels = x_train_targets\n",
    "\n",
    "y = dre.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2653238c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the result:\n",
    "labels = x_train_targets\n",
    "colors = ['darkorange', 'deepskyblue', 'gold', 'lime', 'k', 'darkviolet', 'peru', 'olive',\n",
    "               'midnightblue',\n",
    "               'palevioletred']\n",
    "cmap = matplotlib.colors.ListedColormap(colors[::-1])\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.patch.set_facecolor('#303030')\n",
    "scatter = plt.scatter(y[:, 0], y[:, 1], s=0.1, cmap=cmap, c=labels, alpha=0.5)\n",
    "legend1 = plt.legend(*scatter.legend_elements(), title=\"Classes\", loc='upper right')\n",
    "plt.axis('equal')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57de86af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model (default selected dir: ./):\n",
    "dre.save_model(save_dir='./', model_name='DRE_MNIST')  # The model is saved in '<selected dir>/DRE_model_checkpoint/'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
